# SMS Spam Detection with TF-IDF & Multinomial NaÃ¯ve Bayes

A compact, **fully-reproducible Jupyter notebook** (<kbd>spam_detection_naive_bayes.ipynb</kbd>) that trains and evaluates a text-classification model on the classic SMS Spam Collection dataset.  
In ~60 lines of Python we achieve **â‰ˆ 96 % accuracy** and an **AUC â‰ˆ 0.99**â€”all on a single CPU in seconds.

---

## Table of Contents
1. [Features](#features)  
2. [Quick Start](#quick-start)  
3. [Project Structure](#project-structure)  
4. [Notebook Walk-through](#notebook-walk-through)  
5. [Results Snapshot](#results-snapshot)  
6. [Next Steps](#next-steps)  
7. [License](#license)

---

## Features
- **End-to-end workflow**: data download â†’ preprocessing â†’ train/test split â†’ TF-IDF vectorisation â†’ model fitting â†’ evaluation plots.  
- **Lightweight model**: Multinomial NaÃ¯ve Bayes pairs naturally with sparse TF-IDF features.  
- **Interpretability hooks**: view top â€œspammyâ€ tokens by log-odds.  
- **Diagnostic visuals**: confusion matrix, ROC curve, precisionâ€“recall curve.

---

## Quick Start

### 1 Â· Clone and install
```
git clone https://github.com/&lt;your-user&gt;/sms-spam-nb.git
cd sms-spam-nb
python -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate
```


### 2 Â· Run the notebook
```
jupyter notebook spam_detection_naive_bayes.ipynb
```

> **Tip:** No GPU required, executes in under a minute on most laptops.

---

## Project Structure
```
spam_detection_naive_bayes/
â”‚
â”œâ”€ spam_detection_naive_bayes.ipynb   â† Main notebook (step-by-step tutorial)
â””â”€ README.md                          â† You are here
```

---

## Notebook Walk-through

| Section | What happens |
|---------|--------------|
| **1 Â· Fetch the dataset** | Downloads the SMS Spam Collection via `kagglehub`. |
| **2 Â· Inspect the raw data** | Loads CSV, shows class balance, cleans column names. |
| **3 Â· Split & vectorise** | 80/20 train/test split, converts text to TF-IDF vectors, removes English stop-words. |
| **4 Â· Model training** | Fits `MultinomialNB()` in milliseconds. |
| **5 Â· First-pass metrics** | Accuracy, precision, recall, F1â€”spotlight on spam-recall gap. |
| **6â€“8 Â· Visual diagnostics** | Confusion matrix heatmap, ROC curve (AUC), Precision-Recall curve (AP). |
| **9 Â· â€œSpammyâ€ words** | Lists highest log-odds tokens (`free`, `txt`, `win`, â€¦). |
| **10 Â· Sanity-check messages** | Runs handcrafted examples through the pipeline. |
| **Conclusion** | Recaps strengths & limitations; outlines tuning ideas. |

---

## Results Snapshot
| Metric | Score |
|--------|-------|
| **Accuracy** | 96.7 % |
| **AUC - ROC** | 0.99 |
| **Ham Recall** | 1.00 |
| **Spam Recall** | 0.75 |

ğŸ” **Interpretation:** No legit messages are mis-flagged (ham recall = 1.00), but 25 % of spam slips pastâ€”common for out-of-the-box NB. See notebook for tuning suggestions.

---

## Next Steps
* **Boost spam recall**: class-prior tweaks, add bi-/tri-grams, or switch to linear SVM / logistic regression.  
* **Deploy**: wrap the vectoriser + model in a Flask/FastAPI microservice.  
* **Explainability**: integrate SHAP for per-message feature attributions.  
* **Dataset augmentation**: blend newer SMS/phishing corpora to stay current.

